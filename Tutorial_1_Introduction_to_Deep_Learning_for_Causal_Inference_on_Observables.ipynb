{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 1: Introduction to Deep Learning for Causal Inference on Observables.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kochbj/Deep-Learning-for-Causal-Inference/blob/main/Tutorial_1_Introduction_to_Deep_Learning_for_Causal_Inference_on_Observables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6lEQGN9sI-S"
      },
      "source": [
        "These tutorials are licensed by [Bernard Koch](http://www.github.com/kochbj) under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypM4RTCdy7iV"
      },
      "source": [
        "# Tutorial 1: Introduction to Deep Learning for Causal Inference on Observables\n",
        " \n",
        "The following tutorials are a gentle introduction to building deep learning models for causal inference using the selection on observables identification strategy. In particular, these model are designed to estimate the  average treatment effect (ATE) and the conditional average treatment effect (CATE). The ATE is defined as:\n",
        " \n",
        "$$ATE =\\mathbb{E}[Y(1)-Y(0)]$$\n",
        " \n",
        "where $Y(1)$ and $Y(0)$ are the potential outcomes had the unit received or not received the treatment, respectively. The CATE is defined as,\n",
        " \n",
        "$$CATE =\\mathbb{E}[Y(1)-Y(0)|X=x]$$\n",
        " \n",
        "where $X$ is the set of selected, observable covariates, and $x \\in X$.\n",
        " \n",
        "Because selection on observables is a simple identification strategy, these estimators are simple neural networks. This tutorial is thus also a gentle introduction to writing models in TensorFlow, and getting started coding deep learning models.\n",
        " \n",
        "**These tutorials are for you if:**\n",
        " \n",
        "1. You want a quick and dirty introduction to DL + Selection on Observables literature with minimal math, or...\n",
        " \n",
        "2. You want a gentle introduction to writing  and training custom models in Tensorflow 2 and...\n",
        " \n",
        "3. You have a basic familiarity with causal inference and...\n",
        " \n",
        "4. You have a basic familiarity with Python and object oriented programming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8pWGN7_jn8n"
      },
      "source": [
        "## Why use deep learning for causal inference?\n",
        "\n",
        "1. Appropriately built neural network models are among the **lowest bias** estimators in our statistical arsenal.\n",
        "\n",
        "2. For similar reasons, the complex response surfaces learned by neural networks make them well-suited for estimating **heterogeneous treatment effects**.\n",
        "\n",
        "4. Most excitingly, deep learning has the ability to allow us to control for confounding found in **complex data types like images, text, and networks**.\n",
        "\n",
        "3. Although most of these models don't make theoretical guarantees, representation learning **might be more robust to empirical violations of overlap** than simpler adjustment strategies.\n",
        "\n",
        "5. Although most of these models don't make theoretical guarantees, representation learning **might be more robust to bias induced by including instruments**  in your conditioning covariates.\n",
        "\n",
        "One more point: even if we cannot formally satisfy causal inference assumptions, these architectures are still very useful for **creating interpretable ML models** where we can isolate the contributions of specific covariates to predicting the outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTkpw_cxBq3H"
      },
      "source": [
        "## Notation\n",
        "**Causal identification**\n",
        "\n",
        "- Observed covariates/features: $X$\n",
        "\n",
        "- Potential outcomes: $Y(0)$ and $Y(1)$\n",
        "\n",
        "- Treatment: $T$\n",
        "\n",
        "- Average Treatment Effect: $ATE =\\mathbb{E}[Y(1)-Y(0)]$\n",
        "\n",
        "- Conditional Average Treatment Effect: $CATE =\\mathbb{E}[Y(1)-Y(0)|X=x]$\n",
        "\n",
        "**Deep learning estimation**\n",
        "\n",
        "- Predicted outcomes: $\\hat{Y}(0)$ and $\\hat{Y}(1)$\n",
        "\n",
        "- Outcome modeling functions: $\\hat{Y}(T)=h(X,T)$\n",
        "\n",
        "- Representation functions: $\\Phi(X)$ (producing representations $\\phi$)\n",
        "\n",
        "- Loss functions: $\\mathcal{L}(true,predicted)$, with the mean squared error abbreviated $MSE$ and binary cross-entropy as $BCE$\n",
        "\n",
        "- Estimated CATE: $\\hat{CATE}=(1-2t)(\\hat{{y}}(t)-\\hat{y}(1-t))$\n",
        "\n",
        "- Estimated ATE: $\\hat{ATE}=\\frac{1}{n}\\sum_{i=1}^n\\hat{CATE_i}$\n",
        "\n",
        "\n",
        "## Standard assumptions for causal identification under selection on observables\n",
        "Standard assumptions for model-based causal inference apply here (from [Johansson et al., 2020](https://arxiv.org/pdf/2001.07426.pdf)): \n",
        "1. **Ignorability/Exchangability**.The potential outcomes $Y(0)$, $Y(1)$ and the treatment $T$ are conditionally independent given $X$,\n",
        "$$Y(0),Y(1)\\perp \\!\\!\\! \\perp T|X $$\n",
        "Ignorability specifies that there are no *unmeasured confounders* that affect both treatment and outcome outside of those in the observed covariates/features $X$.\n",
        "\n",
        "\n",
        "2. **Consistency/Stable Unit Treatment Value Assumption (SUTVA)**. Consistency specifies that when a unit recieves treatment, we observe the potential outcome. Moreover, the response of any unit does not vary with the treatment assignment to other units (i.e., no network effects), and the form/level of treatment is homogeneous and consistent across units,\n",
        "$$T=t \\rightarrow Y=Y(T)$$\n",
        "\n",
        "\n",
        "3. **Overlap** In any context $x \\in X$, any treatment $t\\in \\{0,1\\}$ has a non-zero probability of being observed in the data, \n",
        "\n",
        "$$\\forall x \\in X, t\\in\\{0,1\\}:p(T=t|X=x)>0$$\n",
        "\n",
        "Note that the overlap assumption does not require that the empirical data are necessarily balanced, but that the two treatment distributions have common support. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKyjje9UDs2j"
      },
      "source": [
        "## Representation learning as a balancing strategy\n",
        "\n",
        "A core concept in deep learning is the idea that artificial neural networks have the capacity to project a set of complex features $X$ into a useful vector space. When data are transformed into this space, we call the resulting tensor a **representation** ([Goodfellow, et al. 2016](https://www.deeplearningbook.org/contents/representation.html)) (you might also see the term \"embedding\"). For social scientists most comfortable with linear models, we can think about the parameters in each feed-forward layer of a deep neural network as capturing every possible interaction between the values produced by the previous layer. Tasking the network to minimize error on a relevant downstream task encourages it to adjust these interaction parameters to learn useful representations. We can also think about these representation layers as automatically extracting useful  latent covariates/features.\n",
        "\n",
        "The key intuition in this literature is that we want to train neural networks to learn a representation function $\\Phi(X)$ where the data are deconfounded/balanced in the representation space. In other words, the distributions of the representations $\\Phi(X|T=0)$ and $\\Phi(X|T=1)$ are similar.\n",
        "\n",
        "<figure><img src=http://drive.google.com/uc?export=view&id=1pX9MeIn504CTB3GAybLLpzW3QfP9XLgC width=\"900\"><figcaption><a href=https://github.com/maxwshen/iap-cidl>From Shen and Johansson talk 2018</a></figcaption></figure>\n",
        "\n",
        "Note that $\\Phi$ must, in theory, be an invertible function for the  ignorability and overlap assumptions to hold. By invertible we mean that there is an inverse function such that $\\Phi^{-1}(\\Phi(X))=X$.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfgwjo_WUESS"
      },
      "source": [
        "# TARNet (Baseline model)\n",
        "\n",
        "To encourage balanced representations, [Johansson et al., 2017](https://arxiv.org/pdf/1605.03661.pdf) propose a simple two-headed neural network called Treatment Agnostic Regression Network (TARNet). Each head models a separate outcome. One head learns the function $\\hat{Y}(1)=h(\\Phi(X),1)$, and the other head learns the function $\\hat{Y}(0)=h(\\Phi(X),0)$. Both heads backpropagate their gradients to shared representation layers that learn $\\Phi(X)$. Again, the hope is that these representation layers will learn to balance the data because they are used to predict both outcomes.\n",
        "\n",
        "<figure><img src=http://drive.google.com/uc?export=view&id=1bgEfuWqywEmGuGSHeEqZEitL_OHw3Y3F width=\"900\"><figcaption>TARNet architecture originally introduced in <a href=https://arxiv.org/pdf/1605.03661.pdf>Johansson et al, 2017</a>. Dashed lines indicate plug-in estimation of CATE (empirical risk) as described above. Green indicates raw data. Figure from <a href=https://arxiv.org/pdf/2001.07426.pdf>Johansson et al, 2020.</a></figcaption></figure>\n",
        "\n",
        "\n",
        "Other than this architectural change, this is a standard regression DNN where we minimize the factual MSE for each head:\n",
        "\n",
        "$$\\mathcal{L}(Y,h(\\Phi(X),T))=MSE(Y,h(\\Phi(X),T))=\\frac{1}{n}\\sum_{i=1}^n [h(\\Phi(x_i),t_i)-y_i(t_i)]^2$$\n",
        "\n",
        " The complete objective for the network is to minimize the parameters of $h$ and $\\Phi$ for all $n$ units in the training sample such that,\n",
        "\n",
        "\\begin{equation}\n",
        "\\min_{h,\\Phi}\\frac{1}{n}\\sum_{i=1}^n \\mathcal{L}(y_i(t_i),h(\\Phi(x_i),t_i)) + \\lambda \\mathcal{R}(h)\\end{equation}\n",
        "\n",
        "where $\\mathcal{R}(h)$ is a model complexity term (e.g., for $L_2$ regularization) and $\\lambda$ is a hyperparameter chosen by the user.\n",
        "\n",
        "##Estimating Causal Effects\n",
        "After training, we will get two predictions: $\\hat{y}(t)$ and $\\hat{y}(1-t)$. We can estimate the $CATE$ in the testing sample (or full sample since this is inference) as,\n",
        "$$\\hat{CATE}=(1-2t)(\\hat{y}(t)-\\hat{y}(1-t))$$\n",
        "and the average treatment effect as,\n",
        "$$\\hat{ATE}=\\frac{1}{n}\\sum_{i=1}^n\\hat{CATE_i}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUrXNmiAG7zk"
      },
      "source": [
        "## Coding up TARNet\n",
        "\n",
        "Okay, let's build the model! The rest of this tutorial basically annotates Claudia Shi's beautiful [implementation](https://github.com/claudiashi57/dragonnet) of TARNet from her [DragonNet paper](https://arxiv.org/pdf/1906.02120.pdf) (featured in a subsequent tutorial). Tensorflow provides a lot of flexibility for building custom models. As I go along I will try and point out alternative ways we could have done things. If you've never used Keras or Tensorflow 2, I'd recommend going over some standard tutorials first to get your bearings, but otherwise this is about as simple as it gets.\n",
        "\n",
        "First let's get our packages..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_o2BBef1THI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np #numpy is the numerical computing package in python\n",
        "import datetime #we'll use dates to label our logs\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FUS7458U3F0"
      },
      "source": [
        "\n",
        "The next block specifies a function to build the model using Tensorflow 2's functional API. The functional API is one of three API's in Tensorflow (see this [post](https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021) for pros and cons). An example implementation of TARNet in the imperative object-oriented API is in the spoiler below (closer to how it would be implemented in PyTorch).\n",
        "\n",
        "<details><summary>Imperative API Implementation</summary>\n",
        "\n",
        " The same model above might look something like this in the imperative API:\n",
        "```python\n",
        "class TarNet(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 name='tarnet',\n",
        "                 regularization=.01,\n",
        "                 **kwargs):\n",
        "        super(TarNet, self).__init__(name=name, **kwargs)\n",
        "        self.encoder1=Dense(units=200, activation='elu', kernel_initializer='RandomNormal')\n",
        "        self.encoder2=Dense(units=200, activation='elu', kernel_initializer='RandomNormal')\n",
        "        self.encoder3=Dense(units=200, activation='elu', kernel_initializer='RandomNormal')\n",
        "\n",
        "        self.regressor1_y0 = Dense(units=100, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
        "        self.regressor2_y0 = Dense(units=100, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
        "        self.regressorO_y0 = Dense(units=1, activation=None, kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
        "\n",
        "        self.regressor1_y1 = Dense(units=100, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
        "        self.regressor2_y1 = Dense(units=100, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
        "        self.regressorO_y1 = Dense(units=1, activation=None, kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
        "\n",
        "\n",
        "    def call(self,inputs):\n",
        "        x=self.encoder1(inputs)\n",
        "        x=self.encoder2(x)\n",
        "        phi=self.encoder3(x)\n",
        "\n",
        "        out_y0=self.regressor1_y0(phi)\n",
        "        out_y0=self.regressor2_y0(out_y0)\n",
        "        y0=self.regressorO_y0(out_y0)\n",
        "\n",
        "        out_y1=self.regressor1_y1(phi)\n",
        "        out_y1=self.regressor2_y1(out_y1)\n",
        "        y1=self.regressorO_y1(out_y1)\n",
        "\n",
        "        concat=tf.concat([y0,y1,propensity],axis=1)\n",
        "        return concat\n",
        "```\n",
        "</details>\n",
        "\n",
        "The model itself is pretty simple. We use two representation layers with 200 neurons each, and two output layers for each head with 100 neurons each. Because treatment information is implicit in in the two heads, we only need one input: $X$. There are again a couple ways to have multiple outputs in the Functional API, but here we concatenate the two outputs into a list of vectors. We apply regularization to the output heads. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKp8LczJYDAF"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def make_tarnet(input_dim, reg_l2):\n",
        "    '''\n",
        "    The first argument is the column dimension of our data.\n",
        "    It needs to be specified because the functional API creates a static computational graph\n",
        "    The second argument is the strength of regularization we'll apply to the output layers\n",
        "    '''\n",
        "    x = Input(shape=(input_dim,), name='input')\n",
        "\n",
        "    # REPRESENTATION\n",
        "    #in TF2/Keras it is idiomatic to instantiate a layer and pass its inputs on the same line unless the layer will be reused\n",
        "    #Note that we apply no regularization to the representation layers \n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(x)\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_2')(phi)\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_3')(phi)\n",
        "\n",
        "    # HYPOTHESIS\n",
        "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
        "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
        "\n",
        "    # second layer\n",
        "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_2')(y0_hidden)\n",
        "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_2')(y1_hidden)\n",
        "\n",
        "    # third\n",
        "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
        "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
        "\n",
        "    #a convenience \"layer\" that concatenates arrays as columns in a matrix\n",
        "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions])\n",
        "    #the declarations above have specified the computational graph of our network, now we instantiate it\n",
        "    model = Model(inputs=x, outputs=concat_pred)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6VKhI5dkSh3"
      },
      "source": [
        "The `summary` method can be used to confirm that the architecture is specified correctly.\n",
        "\n",
        "One of the advantages of the functional API is that you can also visualize static computational graphs (very similar to the cartoon representation above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxvD3WAwZD47"
      },
      "source": [
        "tarnet_model=make_tarnet(25,.01)\n",
        "\n",
        "print(tarnet_model.summary())\n",
        "tf.keras.utils.plot_model(tarnet_model, show_shapes=True, show_layer_names=True, to_file='tarnet.png')\n",
        "\n",
        "from IPython.display import Image # this just Jupyter notebook stuff\n",
        "Image(retina=True, filename='tarnet.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP8ctAaXW98T"
      },
      "source": [
        "## Specifying the loss function\n",
        "There are again at least four different ways to specify loss functions in Tensorflow2: if you have a standard loss there are built-in options, you can specify them as custom functions, custom objects, or build them into custom layers of your network. Here we've written a function.\n",
        "\n",
        " Note that we compute $\\mathcal{L}(Y(0),h(\\Phi(X),0))$ and $\\mathcal{L}(Y(1),h(\\Phi(X),1))$ separately and just add them to get the whole loss. Tensorflow will apply the gradients appropriately to the different outcome and representation layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPwVW_OwONIP"
      },
      "source": [
        "# every loss function in TF2 takes 2 arguments, a vector of true values and a vector predictions\n",
        "def regression_loss(concat_true, concat_pred):\n",
        "    #computes a standard MSE loss for TARNet\n",
        "    y_true = concat_true[:, 0] #get individual vectors\n",
        "    t_true = concat_true[:, 1]\n",
        "\n",
        "    y0_pred = concat_pred[:, 0]\n",
        "    y1_pred = concat_pred[:, 1]\n",
        "\n",
        "    #Each head outputs a prediction for both potential outcomes\n",
        "    #We use t_true as a switch to only calculate the factual loss\n",
        "    loss0 = tf.reduce_sum((1. - t_true) * tf.square(y_true - y0_pred))\n",
        "    loss1 = tf.reduce_sum(t_true * tf.square(y_true - y1_pred))\n",
        "    #note Shi uses tf.reduce_sum for her losses instead of tf.reduce_mean.\n",
        "    #They should be equivalent but it's possible that having larger gradients accelerates convergence.\n",
        "    #You can always try changing it!\n",
        "    return loss0 + loss1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVhJelhqCMD7"
      },
      "source": [
        "## Data \n",
        "\n",
        "The IHDP dataset used in this example is a naturalistic simulation introduced in [Hill, 2011](https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162?casa_token=b8-rfzagECIAAAAA:QeP7C4lKN6nZ7MkDjJHFrEberXopD9M5qPBMeBqbk84mI_8qGxj01ctgt4jdZtORpu9aZvpVRe07PA) to evaluate estimation of heterogeneous treatment effects ($CATE$). The  25 covariates/features for the 747 units (139 treated) in the dataset were taken from an experiment, but Hill simulated the outcomes to create known counterfactuals. The data are available from Fredrik Johansson's website. IHDP is the de facto benchmark in this literature.\n",
        "\n",
        "<details><summary>Additional details from Hill, 2011</summary>\n",
        "<blockquote>[Hill] used experimental data from the Infant Health and Development Program (IHDP), a randomized experiment that began in 1985, targeted low-birth-weight, premature infants, and provided the treatment group with both intensive high-quality child care and home visits from a trained provider.... [The response surface] is nonlinear and not parallel across treatment conditions, with $Y(0)∼\\mathcal{N}(exp((X+W)\\beta_B),1)$ and $Y(1)∼\\mathcal{N}(X\\beta_B−\\omega^s_B,1)$, where $W$ is an offset matrix of the same dimension as $X$ with every value equal to 0.5, $\\beta_B$ is a vector of regression coefficients (0, 0.1, 0.2, 0.3, 0.4) randomly sampled with probabilities (0.6, 0.1, 0.1, 0.1,0.1). For the sth simulation, $\\omega^s_B$ was chosen in the overlap setting, where we estimate the effect of the treatment on the treated, such that theconditional average treatment effect for the treated equals 4.</blockquote>\n",
        "</details>\n",
        "\n",
        "`y` is the simulated outcome that may represent $Y(0)$ or $Y(1)$ depending on `t`. Note that we rescale it here to improve convergence. `mu_0` and `mu_1` are \"noiseless\" potential outcomes where Hill simply used the mean of the normal distribution described in the spoiler.\n",
        "\n",
        "There are 100 stochastic simulations in this data. For this example we will just use the eighth one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psz99l_n-9po"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.train.npz\n",
        "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.test.npz \n",
        " \n",
        "def load_IHDP_data(training_data,testing_data,i=7):\n",
        "    with open(training_data,'rb') as trf, open(testing_data,'rb') as tef:\n",
        "        train_data=np.load(trf); test_data=np.load(tef)\n",
        "        y=np.concatenate(   (train_data['yf'][:,i],   test_data['yf'][:,i])).astype('float32') #most GPUs only compute 32-bit floats\n",
        "        t=np.concatenate(   (train_data['t'][:,i],    test_data['t'][:,i])).astype('float32')\n",
        "        x=np.concatenate(   (train_data['x'][:,:,i],  test_data['x'][:,:,i]),axis=0).astype('float32')\n",
        "        mu_0=np.concatenate((train_data['mu0'][:,i],  test_data['mu0'][:,i])).astype('float32')\n",
        "        mu_1=np.concatenate((train_data['mu1'][:,i],  test_data['mu1'][:,i])).astype('float32')\n",
        " \n",
        "        data={'x':x,'t':t,'y':y,'t':t,'mu_0':mu_0,'mu_1':mu_1}\n",
        "        data['t']=data['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension \n",
        "        data['y']=data['y'].reshape(-1,1)\n",
        "        \n",
        "        #rescaling y between 0 and 1 often makes training of DL regressors easier\n",
        "        data['y_scaler'] = StandardScaler().fit(data['y'])\n",
        "        data['ys'] = data['y_scaler'].transform(data['y'])\n",
        " \n",
        "    return data\n",
        " \n",
        "data=load_IHDP_data(training_data='./ihdp_npci_1-100.train.npz',testing_data='./ihdp_npci_1-100.test.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixInwwcKmMfO"
      },
      "source": [
        "# Training and Fitting the Model\n",
        "\n",
        "\n",
        "<details><summary>A brief spoiler about training neural networks if you've never done so before.</summary>\n",
        "\n",
        "When you use other types of machine learning models, optimization of the model parameters is typically done for you under the hood and you simply wait for training to finish. In contrast, neural networks have so many parameters that optimization becomes an art.\n",
        "\n",
        "Rather than training on the whole training dataset at once, neural networks are trained on mini-batches of dozens to a few hundred examples. This is a compromise between applying error gradients from a single example (computationally expensive) and using the whole training dataset (expensive in terms of memory; may not work as well for losses that are not perfectly convex). The error gradient is applied to the network parameters after each mini-batch. A complete iteration through all mini-batches in the training set is called an **epoch.** \n",
        "\n",
        "After each epoch we run prediction on the entire validation set. While there are a number of regularization techniques used in DL to prevent overfitting (norms, dropout, batch normalization), the most important is **early stopping.** To prevent overfitting, we wish to stop training after several consecutive epochs where the validation loss has failed to improve. The number of epochs to wait after early stopping is often called a *patience* hyperparameter. \n",
        "\n",
        "The proportion of the gradient the optimizer backpropagates to the parameters is called the **learning rate.** A learning rate that is too small takes a long time to train. A learning rate that is too large will overshoot optima. Learning rate schedulers are used to adaptively slow the learning rate as you get closer to an optimum.\n",
        "\n",
        "---\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "Shi uses the builtin Keras `.fit` infrastructure for training the model which makes things super easy. There are a lot of hyperparameter choices here, but I won't dwell on them because hyperparameter selection will be covered in the next tutorial.\n",
        "\n",
        " In this example we use stochastic gradient descent to optimize the model with an initial learning rate of 1E-4 and momentum of .9. You can also try other optimizers (e.g., ADAM). **While you should experiment with different learning rates, I recommend having a conservative (smaller) learning rate because we really want our estimator to be unbiased.**\n",
        " \n",
        " To avoid overfitting, we stop training deep learning models when the validation loss stops improving. In Tensorflow the `EarlyStopping` callback automatically stops training after a number of epochs with no improvement on the validation loss (`patience` parameter). The `ReduceLROnPlateau` adaptively lowers the learning rate of the optimizer as we approach validation loss plateaus so that the optimizer does not overshoot the current optimum.\n",
        "\n",
        "We use a mini-batch size of 64. Other papers have recommmended batch sizes up to 200 with this dataset. **The batch size is an important consideration for these causal inference architectures because you really want to make sure each mini-batch has both treatment and control examples for the representation layers.** This is obviously less of a problem for datasets with high proportions of treated units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZQB19mL4sON"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "val_split=0.2\n",
        "batch_size=64\n",
        "verbose=1\n",
        "i = 0\n",
        "tf.random.set_seed(i)\n",
        "np.random.seed(i)\n",
        "yt = np.concatenate([data['ys'], data['t']], 1) #we'll use both y and t to compute the loss\n",
        "\n",
        "\n",
        "sgd_callbacks = [\n",
        "        TerminateOnNaN(),\n",
        "        EarlyStopping(monitor='val_loss', patience=40, min_delta=0.), \n",
        "        #40 is Shi's recommendation for this dataset, but you should tune for your data \n",
        "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
        "                          min_delta=0., cooldown=0, min_lr=0),\n",
        "    ]\n",
        "#optimzier hyperparameters\n",
        "sgd_lr = 1e-5\n",
        "momentum = 0.9\n",
        "tarnet_model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
        "                    loss=regression_loss,\n",
        "                    metrics=regression_loss)\n",
        "\n",
        "tarnet_model.fit(x=data['x'],y=yt,\n",
        "                callbacks=sgd_callbacks,\n",
        "                validation_split=val_split,\n",
        "                epochs=300,\n",
        "                batch_size=batch_size,\n",
        "                verbose=verbose)\n",
        "print(\"DONE!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKWKcDkN1GPW"
      },
      "source": [
        "# Estimating the ATE/CATE\n",
        "\n",
        "Now we can do inference on either the whole dataset or a heldout testing sample. For simplicity, we just use the whole dataset here. \n",
        "\n",
        "We'll also plot our CATE estimates against the the true cates from the simulation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS5RYt3F01ba"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "concat_pred=tarnet_model.predict(data['x'])\n",
        "#dont forget to rescale the outcome before estimation!\n",
        "y0_pred = data['y_scaler'].inverse_transform(concat_pred[:, 0])\n",
        "y1_pred = data['y_scaler'].inverse_transform(concat_pred[:, 1])\n",
        "cate_pred=y1_pred-y0_pred\n",
        "cate_true=data['mu_1']-data['mu_0'] #Hill's noiseless true values\n",
        "ate_pred=tf.reduce_mean(cate_pred)\n",
        "print(\"Estimated ATE (True is 4):\", ate_pred.numpy(),'\\n\\n')\n",
        "\n",
        "print(\"Individualized CATE Estimates: BLUE\")\n",
        "print(pd.Series(cate_pred).plot.kde(color='blue'))\n",
        "print(\"Individualized CATE True: Green\")\n",
        "print(pd.Series(cate_true).plot.kde(color='green'))\n",
        "\n",
        "print(\"\\nError CATE Estimates: RED\")\n",
        "print(pd.Series(cate_pred-cate_true).plot.kde(color='red'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yO3b-S10177"
      },
      "source": [
        "While our estimates have a broader spread than the real values, we haven't done any hyperparameter optimization yet so we can definitely do better. That's the focus of the next tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLFNVjnS_fTw"
      },
      "source": [
        "Of course we can also break down these heterogeneous treatment effects to see if we can find any interesting patterns using, for example, Google's [Facet Dive](https://pair-code.github.io/facets/). This is just demonstrative since our covariates are meaningless in the simulation, but it's still cool. The Facet Dive is now built into TensorBoard. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcqW8oZiA23B",
        "cellView": "form"
      },
      "source": [
        "#@title Explore Heterogeneity Using the Facet Dive\n",
        "\n",
        "data['cate_pred']=cate_pred\n",
        "facet_df=pd.DataFrame(data['x'])\n",
        "facet_df['t']=data['t']\n",
        "facet_df['y']=data['y']\n",
        "facet_df['cate_pred']=data['cate_pred']\n",
        "\n",
        "\n",
        "# Display the Dive visualization for the training data.\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "jsonstr = facet_df.to_json(orient='records')\n",
        "HTML_TEMPLATE = \"\"\"\n",
        "        <script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
        "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
        "        <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n",
        "        <script>\n",
        "          var data = {jsonstr};\n",
        "          document.querySelector(\"#elem\").data = data;\n",
        "        </script>\"\"\"\n",
        "html = HTML_TEMPLATE.format(jsonstr=jsonstr)\n",
        "display(HTML(html))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG3IM93059Qx"
      },
      "source": [
        "# Thats it!\n",
        "\n",
        "- In this tutorial we introduce representation learning for causal inference.\n",
        "\n",
        "- We learned how to write custom models using the functional API and custom losses in TF2.\n",
        "\n",
        "- We built a TARNet model and tested it on the IHDP data.\n",
        "\n",
        "# Up next...\n",
        "- In the [second tutorial](https://colab.research.google.com/drive/1y9i8koqPqs8JSyVHkdZmjGEW6ntqPV73?usp=sharing) we will dig a bit deeper into model design. We'll learn how to assess convergence using Tensorboard, and tailor TarNet models to your dataset through hyperparameter optimization using [kerastuner](https://keras-team.github.io/keras-tuner/).\n",
        "\n",
        "- In the [third tutorial](https://colab.research.google.com/drive/19JJNyGAvSJCY8xP8vkVUXFf3-uEdDuss?usp=sharing), we'll introduce some more sophisticated elaborations of TARNet built on semiparametric theory shown in [Shi et al., 2019](https://arxiv.org/pdf/1906.02120.pdf).\n",
        "\n",
        "- In the [fourth tutorial](https://colab.research.google.com/drive/1d8kvEXk_j268rrYq8QC_hbkfhLmp742Y?usp=sharing), we demonstrate TARNet extensions using integral probability metrics from [Shalit et al., 2017](https://arxiv.org/abs/1606.03976), [Johansson et al. 2018](https://arxiv.org/abs/1903.03448), and [Johansson et al., 2020](https://arxiv.org/abs/2001.07426)."
      ]
    }
  ]
}