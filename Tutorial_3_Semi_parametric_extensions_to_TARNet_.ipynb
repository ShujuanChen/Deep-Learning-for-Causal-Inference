{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 3: Semi-parametric extensions to TARNet .ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kochbj/Deep-Learning-for-Causal-Inference/blob/main/Tutorial_3_Semi_parametric_extensions_to_TARNet_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQGUMoIo7aJ"
      },
      "source": [
        "These tutorials are licensed by [Bernard Koch](http://www.github.com/kochbj) under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKGAwpt_Dp9b"
      },
      "source": [
        "# Tutorial 3: Semi-parametric extensions to TARNet \n",
        "\n",
        "In practice, TARNet is a pretty low bias $CATE$ estimator, but it doesn't have a strong theoretical motivation. In this short tutorial we elaborate on the base TarNet model with some modifications using inverse propensity-score weighting that provide consistency guarantees from semi-parametric theory. These models are featured in [Shi et al., 2019](https://arxiv.org/pdf/1906.02120.pdf), and the code is adapted from Shi's [excellent GitHub repository](https://github.com/claudiashi57/dragonnet).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFjT_fDuppay"
      },
      "source": [
        "## Notation\n",
        "**Causal identification**\n",
        "\n",
        "- Observed covariates/features: $X$\n",
        "\n",
        "- Potential outcomes: $Y(0)$ and $Y(1)$\n",
        "\n",
        "- Treatment: $T$\n",
        "\n",
        "- Average Treatment Effect: $ATE =\\mathbb{E}[Y(1)-Y(0)]$\n",
        "\n",
        "- Conditional Average Treatment Effect: $CATE =\\mathbb{E}[Y(1)-Y(0)|X=x]$\n",
        "\n",
        "\n",
        "**Deep learning estimation**\n",
        "\n",
        "- Predicted outcomes: $\\hat{Y}(0)$ and $\\hat{Y}(1)$\n",
        "\n",
        "- Outcome modeling functions: $\\hat{Y}(T)=h(X,T)$ \n",
        "\n",
        "- Representation functions: $\\Phi(X)$ (producing representations $\\phi$)\n",
        "\n",
        "- Propensity score function:\n",
        "$\\pi(X,T)=P(T|X)$ </br>*where $\\pi(X,1)=P(T=1|X)$ and $\\pi(X,0)=1-\\pi(X,1)$* \n",
        "\n",
        "- Loss functions: $\\mathcal{L}(true,predicted)$, with the mean squared error abbreviated $MSE$ and binary cross-entropy as $BCE$\n",
        "\n",
        "- Estimated CATE: $\\hat{CATE}=(1-2t)(\\hat{{y}}(t)-\\hat{y}(1-t))$\n",
        "\n",
        "- Estimated ATE: $\\hat{ATE}=\\frac{1}{n}\\sum_{i=1}^n\\hat{CATE_i}$\n",
        "\n",
        "- Nearest-neighbor PEHE (approximate variance in $\\hat{CATE}$ error):\n",
        "$$PEHE_{nn}=\\frac{1}{N}\\sum_{i=1}^N{(\\underbrace{(1−2t_i)(y_i(t_i)−y_i^{nn}(1-t_i)}_{CATE_{nn}}−\\underbrace{(h(\\Phi(x),1)−h(\\Phi(x),0)))}_{\\hat{CATE}}}^2$$ for nearest neighbor $j$ of each unit $i$ in representation space such that $t_j\\neq t_i$:\n",
        "  $$y_i^{nn}(1-t_i) = \\min_{j\\in (1-T)}||\\Phi(x_i|t_i)-\\Phi(x_j|1-t_i)||_2$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-tZX7GTqrlH"
      },
      "source": [
        "## Treatment Modeling in Neural Networks\n",
        " \n",
        "Beyond outcome modeling, another approach to reducing confounding is adjusting for selection into treatment. This is typically done using the *propensity score*. If the $ATE$ is identifiable by adjusting for $X$, then the propensity score $\\pi(X,T)=P(T|X)$ is sufficient to identify the $ATE$ as well (Rosenbaum and Rubin, 1983). We can estimate the ATE using inverse propensity score weighting:\n",
        " \n",
        "$\\hat{ATE}=[\\frac{T}{\\pi(X,T)}-\\frac{1-T}{\\pi(X,1-T)}]\\cdot Y$\n",
        " \n",
        "To use the IPW estimator with a neural network, we can trivially add a third \"head\" to predict the treatment from the representation $\\Phi$ (actually if we *just* wanted to do IPW we don't need the other two heads at all),\n",
        " \n",
        "$\\hat{ATE}=[\\frac{T}{\\pi(\\Phi(X),T)}-\\frac{1-T}{\\pi(\\Phi(X),1-T)}]\\cdot Y$\n",
        " \n",
        " This is the \"Dragonnet\" architecture from [Shi et al., 2019](https://arxiv.org/pdf/1906.02120.pdf).\n",
        " \n",
        "<figure><img src=http://drive.google.com/uc?export=view&id=1E20cDRbwvJNdDChqSs0Qp-SNyklxt_rQ width=\"900\"><figcaption>Dragonnet architecture introduced in Shi et al., 2019. This is just TARNet with a third head (single neuron) predicting the propensity score $P(T)=\\pi(\\Phi(X),T)$.</a></figcaption></figure>\n",
        " \n",
        "The third head could be implemented as a single neuron (as in DragonNet) or using additional layers as in ([Johansson et al. 2018](https://arxiv.org/abs/1903.03448), and [Johansson et al., 2020](https://arxiv.org/abs/2001.07426)) to produce a scalar propensity score $P(T|\\Phi(X))=\\pi(\\Phi(X),T)$.\n",
        " \n",
        "The loss function for this network looks like this:\n",
        "$$\\underset{\\phi,\\pi,h}{\\arg \\min}\\ MSE(Y,h(\\Phi(X),T)) + \\alpha \\cdot \\text{BCE}(T,\\pi(\\Phi(X),T))$$\n",
        "with $\\alpha$ being a hyperparameter to balance the two objectives.\n",
        " \n",
        "Below we break down more sophisticated ways that the propensity score is used in [Shi et al., 2019](https://arxiv.org/pdf/1906.02120.pdf) from semi-parametric estimation theory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEq7OZqcJS-C"
      },
      "source": [
        "## Semi-parametric theory in three paragraphs\n",
        "\n",
        "The application of semi-parametric theory to causal inference (as far as I understand it), is focused on estimating a target parameter of a distribution $P$ of treatment effects $T(P):=ATE$. While we do not know the true distribution of treatment effects because we lack counterfactuals, we do know some parameters of this distribution (e.g., the treatment assignment mechanism). We can encode these  constraints in the form of a likelihood that parametrically defines a set of possible approximate distributions of $P$ from our existing data that we'll call $\\mathcal{P}$. Within this set there is a sample-inferred distribution $\\tilde{P}\\in\\mathcal{P}$, that we can use to estimate $T(P)$ using $T(\\tilde{P})$.\n",
        "\n",
        "### Picking $\\tilde{P}$\n",
        "\n",
        "Regardless of $\\tilde{P}$ chosen, $\\tilde{P}\\neq P \\therefore T(\\tilde{P})\\neq T(P)$. We don't really know how to pick $\\tilde{P}$ with finite data to get the best estimate $T(\\tilde{P})$. We can maximize our likelihood function to pick $\\tilde{P}$, but there are a lot of \"nuisance\" parameters in the likelihood that are not our target that we don't really care about estimating accurately, so this won't necessarily give us the best estimate of $T(P)$. This is where **influence curves** come in. \n",
        " \n",
        " We're going to define a \"nudge\" parameter $\\epsilon$ that moves $\\tilde{P}$ closer to $P$ (thus moving $T(\\tilde{P})$ closer to $T(P)$). An influence curve of $T(P)$ tells us how changes in $\\epsilon$ will induce changes in $T(P+\\epsilon(\\tilde{P}-P))$. We'll use this influence curve to fit $\\epsilon$ to get the best approximation of $T(P)$ that we can. In particular, there is a specific **efficient influence curve (EIC)** that provides us with the lowest variance estimates of $T(P)$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsiMt0LSlt6v"
      },
      "source": [
        "# Part1: AIPW\n",
        "\n",
        "The augmented inverse propensity weighting estimator (AIPW or sometimes AIPTW) is an estimator\n",
        "that solves the efficient influence curve estimating equation for the ATE directly (i.e.,  without a nudge parameter). \n",
        "\n",
        "In AIPW (and TMLE), we set the mean of the EIC estimating equation equal to zero which allows us to use it to estimate the $ATE$ linearly. The estimating equation models both the outcome and the treatment. We can specify it as:\n",
        "\n",
        "$EIC = \\frac{1}{N}\\sum_{i=1}^N{[(\\frac{T}{\\pi(\\Phi(X),1)}-\\frac{1-T}{\\pi(\\Phi(X),0)})[Y-h(\\Phi(X),T)] +[h(\\Phi(X),1)-h(\\Phi(X),0)]}]-ATE$\n",
        "\n",
        "$(\\text{Set mean of EIC to 0})$\n",
        "\n",
        "\n",
        "$ATE = \\frac{1}{N}\\sum_{i=1}^N{[\\underbrace{\\underbrace{(\\frac{T}{\\pi(\\Phi(X),1)}-\\frac{1-T}{\\pi(\\Phi(X),0)})}_{\\text{Treatment Modeling}}\\times\\underbrace{[Y-h(\\Phi(X),T)]}_{\\text{Residual Confounding}}}_{\\text{Adjustment}} +\\underbrace{[h(\\Phi(X),1)-h(\\Phi(X),0)]}_{\\text{Outcome Modeling}}}]$\n",
        "\n",
        "There is another interpretation of the AIPW as a \"doubly robust\" estimator. As a doubly robust estimator, we are effectively using Dragonnet to do outcome modeling of $T(\\tilde{P})$ in the second term, but account for any residual confounding (second part of the first term) using a function of the propensity score. Doubly robust estimators are appealing because they will produce a consistent estimate of the $ATE$ if either $\\pi$ or $h$ is estimated consistently, and are efficient if both are estimated correctly to solve the estimating equation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prhamsURLmjw"
      },
      "source": [
        "## Implementing AIPW\n",
        "\n",
        "Let's begin by implementing AIPW with TARNet. We only need to add the propensity score head to the network and write a new loss function. \n",
        "\n",
        "Because our loss function has a hyperparameter, we'll now need to either add a closure within our [custom loss function](https://towardsdatascience.com/creating-custom-loss-functions-using-tensorflow-2-96c123d5ce6c), or write a custom loss object. I don't like closures, so let's do an object. \n",
        "\n",
        "We'll call this `StandardLoss` because it's the \"standard\" machine learning loss for each of the three heads of our network: $MSE$ for the $h(\\Phi(X),T)$ heads, and binary crossentropy ($BCE$) for the propensity score head $\\pi(\\Phi(X),T)$. If you're not familiar with binary crossentropy/log loss, it's the standard binary classification loss used in deep learning and used for likelihood maximization in logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wgc7wTySg24"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.metrics import binary_accuracy\n",
        "from tensorflow.keras.losses import Loss\n",
        "def make_aipw(input_dim, reg_l2):\n",
        "\n",
        "    x = Input(shape=(input_dim,), name='input')\n",
        "    # representation\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(x)\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_2')(phi)\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_3')(phi)\n",
        "\n",
        "    # HYPOTHESIS\n",
        "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
        "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
        "\n",
        "    # second layer\n",
        "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_2')(y0_hidden)\n",
        "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_2')(y1_hidden)\n",
        "\n",
        "    # third\n",
        "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
        "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
        "\n",
        "    #propensity prediction\n",
        "    #Note that the activation is actually sigmoid, but we will squish it in the loss function for numerical stability reasons\n",
        "    t_prediction = Dense(units=1,activation=None,name='t_prediction')(phi)\n",
        "\n",
        "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,t_prediction,phi])\n",
        "    model = Model(inputs=x, outputs=concat_pred)\n",
        "    return model\n",
        "\n",
        "class Base_Loss(Loss):\n",
        "    #initialize instance attributes\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.name='standard_loss'\n",
        "\n",
        "    def split_pred(self,concat_pred):\n",
        "        #generic helper to make sure we dont make mistakes\n",
        "        preds={}\n",
        "        preds['y0_pred'] = concat_pred[:, 0]\n",
        "        preds['y1_pred'] = concat_pred[:, 1]\n",
        "        preds['t_pred'] = concat_pred[:, 2]\n",
        "        preds['phi'] = concat_pred[:, 3:]\n",
        "        return preds\n",
        "\n",
        "    #for logging purposes only\n",
        "    def treatment_acc(self,concat_true,concat_pred):\n",
        "        t_true = concat_true[:, 1]\n",
        "        p = self.split_pred(concat_pred)\n",
        "        #Since this isn't used as a loss, I've used tf.reduce_mean for interpretability\n",
        "        return tf.reduce_mean(binary_accuracy(t_true, tf.math.sigmoid(p['t_pred']), threshold=0.5))\n",
        "\n",
        "    def treatment_bce(self,concat_true,concat_pred):\n",
        "        t_true = concat_true[:, 1]\n",
        "        p = self.split_pred(concat_pred)\n",
        "        lossP = tf.reduce_sum(binary_crossentropy(t_true,p['t_pred'],from_logits=True))\n",
        "        return lossP\n",
        "    \n",
        "    def regression_loss(self,concat_true,concat_pred):\n",
        "        y_true = concat_true[:, 0]\n",
        "        t_true = concat_true[:, 1]\n",
        "        p = self.split_pred(concat_pred)\n",
        "        loss0 = tf.reduce_sum((1. - t_true) * tf.square(y_true - p['y0_pred']))\n",
        "        loss1 = tf.reduce_sum(t_true * tf.square(y_true - p['y1_pred']))\n",
        "        return loss0+loss1\n",
        "\n",
        "    def standard_loss(self,concat_true,concat_pred):\n",
        "        lossR = self.regression_loss(concat_true,concat_pred)\n",
        "        lossP = self.treatment_bce(concat_true,concat_pred)\n",
        "        return lossR + self.alpha * lossP\n",
        "\n",
        "    #compute loss\n",
        "    def call(self, concat_true, concat_pred):        \n",
        "        return self.standard_loss(concat_true,concat_pred)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voC6EVXK0Kr6"
      },
      "source": [
        "Now let's add AIPW to our callback.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0yymrxg8Lct"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "def pdist2sq(A, B):\n",
        "    #helper for PEHEnn\n",
        "    #calculates squared euclidean distance between rows of two matrices  \n",
        "    #https://gist.github.com/mbsariyildiz/34cdc26afb630e8cae079048eef91865\n",
        "    # squared norms of each row in A and B\n",
        "    na = tf.reduce_sum(tf.square(A), 1)\n",
        "    nb = tf.reduce_sum(tf.square(B), 1)    \n",
        "    # na as a row and nb as a column vectors\n",
        "    na = tf.reshape(na, [-1, 1])\n",
        "    nb = tf.reshape(nb, [1, -1])\n",
        "    # return pairwise euclidean difference matrix\n",
        "    D=tf.reduce_sum((tf.expand_dims(A, 1)-tf.expand_dims(B, 0))**2,2) \n",
        "    return D\n",
        "\n",
        "#https://towardsdatascience.com/implementing-macro-f1-score-in-keras-what-not-to-do-e9f1aa04029d\n",
        "class AIPW_Metrics(Callback):\n",
        "    def __init__(self,data, verbose=0):   \n",
        "        super(AIPW_Metrics, self).__init__()\n",
        "        self.data=data #feed the callback the full dataset\n",
        "        self.verbose=verbose\n",
        "\n",
        "        #needed for PEHEnn; Called in self.find_ynn\n",
        "        self.data['o_idx']=tf.range(self.data['t'].shape[0])\n",
        "        self.data['c_idx']=self.data['o_idx'][self.data['t'].squeeze()==0] #These are the indices of the control units\n",
        "        self.data['t_idx']=self.data['o_idx'][self.data['t'].squeeze()==1] #These are the indices of the treated units\n",
        "    \n",
        "    def split_pred(self,concat_pred):\n",
        "        preds={}\n",
        "        preds['y0_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 0])\n",
        "        preds['y1_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 1])\n",
        "        preds['t_pred'] = concat_pred[:, 2]\n",
        "        preds['phi'] = concat_pred[:, 3:]\n",
        "        return preds\n",
        "\n",
        "    def find_ynn(self, Phi):\n",
        "        #helper for PEHEnn\n",
        "        PhiC, PhiT =tf.dynamic_partition(Phi,tf.cast(tf.squeeze(self.data['t']),tf.int32),2) #separate control and treated reps\n",
        "        dists=tf.sqrt(pdist2sq(PhiC,PhiT)) #calculate squared distance then sqrt to get euclidean\n",
        "        yT_nn_idx=tf.gather(self.data['c_idx'],tf.argmin(dists,axis=0),1) #get c_idxs of smallest distances for treated units\n",
        "        yC_nn_idx=tf.gather(self.data['t_idx'],tf.argmin(dists,axis=1),1) #get t_idxs of smallest distances for control units\n",
        "        yT_nn=tf.gather(self.data['y'],yT_nn_idx,1) #now use these to retrieve y values\n",
        "        yC_nn=tf.gather(self.data['y'],yC_nn_idx,1)\n",
        "        y_nn=tf.dynamic_stitch([self.data['t_idx'],self.data['c_idx']],[yT_nn,yC_nn]) #stitch em back up!\n",
        "        return y_nn\n",
        "\n",
        "    def PEHEnn(self,concat_pred):\n",
        "        p = self.split_pred(concat_pred)\n",
        "        y_nn = self.find_ynn(p['phi']) #now its 3 plus because \n",
        "        cate_nn_err=tf.reduce_mean( tf.square( (1-2*self.data['t']) * (y_nn-self.data['y']) - (p['y1_pred']-p['y0_pred']) ) )\n",
        "        return cate_nn_err\n",
        "\n",
        "    def ATE(self,concat_pred):\n",
        "        p = self.split_pred(concat_pred)\n",
        "        return p['y1_pred']-p['y0_pred']\n",
        "\n",
        "    def PEHE(self,concat_pred):\n",
        "        #simulation only\n",
        "        p = self.split_pred(concat_pred)\n",
        "        cate_err=tf.reduce_mean( tf.square( ( (self.data['mu_1']-self.data['mu_0']) - (p['y1_pred']-p['y0_pred']) ) ) )\n",
        "        return cate_err \n",
        "   \n",
        "    #THIS IS THE NEW PART\n",
        "    def AIPW(self,concat_pred):\n",
        "        p = self.split_pred(concat_pred)\n",
        "        t_pred=tf.math.sigmoid(p['t_pred'])\n",
        "        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n",
        "        y_pred = p['y0_pred'] * (1 - self.data['t']) + p['y1_pred'] * self.data['t']\n",
        "        #cc stands for clever covariate which is I think what it's called in TMLE lit\n",
        "        cc = self.data['t'] * (1.0 / p['t_pred']) - (1.0 - self.data['t']) / (1.0 - p['t_pred'])\n",
        "        cate = cc * (self.data['y'] - y_pred) + p['y1_pred'] - p['y0_pred']\n",
        "        return cate\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        concat_pred=self.model.predict(self.data['x'])\n",
        "        #Calculate Empirical Metrics        \n",
        "        ate_pred=tf.reduce_mean(self.ATE(concat_pred)); tf.summary.scalar('ate', data=ate_pred, step=epoch)\n",
        "        pehe_nn=self.PEHEnn(concat_pred); tf.summary.scalar('cate_nn_err', data=tf.sqrt(pehe_nn), step=epoch)\n",
        "        aipw=tf.reduce_mean(self.AIPW(concat_pred)); tf.summary.scalar('aipw', data=aipw, step=epoch)\n",
        "        \n",
        "        #Simulation Metrics\n",
        "        ate_true=tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n",
        "        ate_err=tf.abs(ate_true-ate_pred); tf.summary.scalar('ate_err', data=ate_err, step=epoch)\n",
        "        pehe =self.PEHE(concat_pred); tf.summary.scalar('cate_err', data=tf.sqrt(pehe), step=epoch)\n",
        "        aipw_err =self.PEHE(concat_pred); tf.summary.scalar('aipw_err', data=aipw_err, step=epoch)\n",
        "        out_str=f' — ate_err: {ate_err:.4f}  — aipw_err: {aipw_err:.4f} — cate_err: {tf.sqrt(pehe):.4f} — cate_nn_err: {tf.sqrt(pehe_nn):.4f} '\n",
        "        \n",
        "        if self.verbose > 0: print(out_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMuLgqvdKIes"
      },
      "source": [
        "Now reload our data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw_66IoIt5_G"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.train.npz\n",
        "!wget -nc http://www.fredjo.com/files/ihdp_npci_1-100.test.npz \n",
        "\n",
        "def load_IHDP_data(training_data,testing_data,i=7):\n",
        "    with open(training_data,'rb') as trf, open(testing_data,'rb') as tef:\n",
        "        train_data=np.load(trf); test_data=np.load(tef)\n",
        "        y=np.concatenate(   (train_data['yf'][:,i],   test_data['yf'][:,i])).astype('float32') #most GPUs only compute 32-bit floats\n",
        "        t=np.concatenate(   (train_data['t'][:,i],    test_data['t'][:,i])).astype('float32')\n",
        "        x=np.concatenate(   (train_data['x'][:,:,i],  test_data['x'][:,:,i]),axis=0).astype('float32')\n",
        "        mu_0=np.concatenate((train_data['mu0'][:,i],  test_data['mu0'][:,i])).astype('float32')\n",
        "        mu_1=np.concatenate((train_data['mu1'][:,i],  test_data['mu1'][:,i])).astype('float32')\n",
        "\n",
        "        data={'x':x,'t':t,'y':y,'t':t,'mu_0':mu_0,'mu_1':mu_1}\n",
        "        data['t']=data['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension \n",
        "        data['y']=data['y'].reshape(-1,1)\n",
        "        \n",
        "        #rescaling y between 0 and 1 often makes training of DL regressors easier\n",
        "        data['y_scaler'] = StandardScaler().fit(data['y'])\n",
        "        data['ys'] = data['y_scaler'].transform(data['y'])\n",
        "\n",
        "    return data\n",
        "\n",
        "data=load_IHDP_data(training_data='./ihdp_npci_1-100.train.npz',testing_data='./ihdp_npci_1-100.test.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhOKnCKSq1oN"
      },
      "source": [
        "Now we're ready to train. Note that I did something I think is nifty this time: I wrote my sublosses as having `y_true` and `y_pred` arguments so I could add them as metrics in `.fit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMYxPCc1LeCC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, TerminateOnNaN\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "val_split=0.2\n",
        "batch_size=64\n",
        "verbose=1\n",
        "i = 0\n",
        "tf.random.set_seed(i)\n",
        "np.random.seed(i)\n",
        "yt = np.concatenate([data['ys'], data['t']], 1)\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
        "file_writer.set_as_default()\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "sgd_callbacks = [\n",
        "        TerminateOnNaN(),\n",
        "        EarlyStopping(monitor='val_loss', patience=40, min_delta=0.),\n",
        "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
        "                          min_delta=0., cooldown=0, min_lr=0),\n",
        "        tensorboard_callback,\n",
        "        AIPW_Metrics(data,verbose=verbose)\n",
        "        ]\n",
        "      \n",
        "\n",
        "sgd_lr = 1e-5\n",
        "momentum = 0.9\n",
        "\n",
        "aipw_model=make_aipw(data['x'].shape[1],.01)\n",
        "aipw_loss=Base_Loss(alpha=1.0)\n",
        "\n",
        "aipw_model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
        "                    loss=aipw_loss,\n",
        "                    metrics=[aipw_loss,aipw_loss.regression_loss,aipw_loss.treatment_acc]\n",
        "                   )\n",
        "\n",
        "aipw_model.fit(x=data['x'],y=yt,\n",
        "                  callbacks=sgd_callbacks,\n",
        "                  validation_split=val_split,\n",
        "                  epochs=300,\n",
        "                  batch_size=batch_size,\n",
        "                  verbose=verbose)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnyNZhVnhPaf"
      },
      "source": [
        "## Reviewing results in Tensorboard\n",
        "\n",
        "Let's do a quick comparison to last tutorial where we ran the exact same network without the propensity score loss.\n",
        "\n",
        "If we look at `treatment_acc`, it's clear that Dragonnet is learning the treatment information. We can also see that there is only a very slight penalty in the network's ability to predict the outcomes (`ate_err`).\n",
        "\n",
        "It's hard to say whether any other performance differences are significant without doing hyperparameter tuning under both scenarios and looking across multiple simulations. For what it's worth, the `aipw_err` is slightly worse than the raw `ate_err` but it's pretty close, and the statistical guarantees are definitely worth something.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdiyf5RIJSAM"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYoM0Hr0NgnM"
      },
      "source": [
        "The issue with inverse propensity score weighting estimators is that the weights are unstable for units that have a propensity score close to 0 or 1. In the case of the AIPW equation above, it can potentially produce estimates of treatment that are less than zero or greater than one. This is one of the practical motivations for using nudge parameters as in TMLE or Targeted Regularization.\n",
        "\n",
        "----   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_1DTqmIlvxt"
      },
      "source": [
        "# Part 2: Targeted Regularization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC4o8gP0i8Gq"
      },
      "source": [
        "\n",
        "## Aside: Targeted Maximum Likelihood Estimation Algorithm\n",
        "\n",
        "We won't implement Targeted Maximum Likelihood Estimation (TMLE) *per se*, but \"Targeted Regularization\" is closely related so it's useful to see it first.\n",
        "\n",
        "TMLE is an iterative procedure where we actually use the nudge parameter $\\epsilon$ to reduce bias when we fit the EIC estimating equation. We then calculate $\\hat{ATE}$ by using nudged variants of our outcome predictions (see below). \n",
        "\n",
        "We begin again by setting the EIC equation to 0. \n",
        "\n",
        "$$EIC = 0 = \\frac{1}{N}\\sum_{i=1}^N{[\\underbrace{\\underbrace{(\\frac{T}{\\pi(x,1)}-\\frac{1-T}{\\pi(x,0)})}_{\\text{Treatment Modeling}}\\times\\underbrace{(Y-h(x,T))}_{\\text{Residual Confounding}}}_{\\text{Adjustment}}] +\\underbrace{[h(x,1)-h(x,0)]}_{\\text{Outcome Modeling}}}]-ATE$$\n",
        "$$ATE = \\frac{1}{N}\\sum_{i=1}^N{[\\underbrace{\\underbrace{(\\frac{T}{\\pi(x,1)}-\\frac{1-T}{\\pi(x,0)})}_{\\text{Treatment Modeling}}\\times\\underbrace{(Y-h(x,T))}_{\\text{Residual Confounding}}}_{\\text{Adjustment}}] +\\underbrace{[h(x,1)-h(x,0)]}_{\\text{Outcome Modeling}}}]$$\n",
        "The TMLE procedure consists of four **consecutive** steps:\n",
        "1. Fit $h$ by predicting outcomes (e.g., using TARNet) and minimizing $MSE(Y,h(X,T))$\n",
        "2. Fit $\\pi$ by predicting treatment (e.g., using logistic regression) and $BCE(T,\\pi(X,T))$\n",
        "3. Plug-in $h$ and $\\pi$ functions to fit $\\epsilon$ and estimate $h^{*}(X,T)$ where,\n",
        "$$h^{*}(X,T)=h(X,T)+(\\frac{T}{\\pi(X,T)}-\\frac{1-T}{\\pi(X,1-T)})\\times \\epsilon$$\n",
        "by minimizing $MSE(Y,h^{*}(X,T))$.\n",
        "\n",
        "(If you look at the EIC, this is equivalent to minimizing the \"Adjustment\" part.)\n",
        "\n",
        "4. Plug-in $h^*(X,T)$ to estimate $\\hat{ATE}$:\n",
        "$$\\hat{ATE}=\\frac{1}{N}\\sum_{i=1}^N{ h^*(x,1)}-{ h^*(x,0)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeAejiJGjILj"
      },
      "source": [
        "## Targeted Regularization\n",
        "\n",
        "Targeted Regularization, introduced in [Shi et al., 2019](https://arxiv.org/pdf/1906.02120.pdf), takes TMLE and adapts it for a neural network loss function. The main difference is that steps 1 and 2 above are done concurrently by Dragonnet, and that the loss functions for the first three steps are combined into a single loss applied to the whole network at the end of each batch. It requires adding a single free parameter to the Dragonnet network for $\\epsilon$.\n",
        "\n",
        " At a very intuitive level, Targeted Regularization is appealing because it introduces a loss function to TARNet that explicitly encourages the network to learn the treatment effect distribution and not just the outcome distribution. The Targeted Regularization procedure proceeds as follows:\n",
        "\n",
        "In each epoch:\n",
        "<ol>\n",
        "  <li>\n",
        "    <ol type=\"a\">\n",
        "    <li>\n",
        "    Use Dragonnet to predict $h(\\Phi(X),T)$ and $\\pi(\\Phi(X),T)$.\n",
        "    </li>\n",
        "    <li>\n",
        "    Calculate the standard ML loss for the network using a hyperparameter $\\alpha$:\n",
        "    $$MSE(Y,h(\\Phi(X),T)) + \\alpha \\cdot BCE(\\pi(\\Phi(X),T))$$\n",
        "    </li>\n",
        "    </ol>\n",
        "  </li>\n",
        "  <li>\n",
        "  <ol type=\"a\">\n",
        "  <li> Compute $h^{*}(\\Phi(X),T)$ as above,\n",
        "  $$h^{*}(\\Phi(x),T)=h(\\Phi(x),T)+(\\frac{T}{\\pi(\\Phi(X),T)}-\\frac{1-T}{\\pi(\\phi(X),1-T)})\\times \\epsilon$$ </li>\n",
        "  <li> Calculate the targeted regularization loss: $MSE(Y,h^*(\\Phi(X),T))$ </li>\n",
        "  </ol>\n",
        "  </li>\n",
        "  <li> Combine and minimize the losses from 1 and 2 using a hyperparameter $\\beta$,\n",
        "    $$\\underset{\\Phi,h,\\epsilon}{\\arg \\min}= [MSE(Y,h(\\Phi(X),T)) + \\alpha \\cdot \\text{BCE}(T,\\pi(\\Phi(X,T))]+\\beta\\cdot MSE(Y,h^*(\\Phi(X),T))$$ </li>\n",
        "</ol>\n",
        "\n",
        "**Step 3 of Targeted Regularization is exactly equivalent to minimizing $\\beta \\cdot EIC$.** \n",
        "\n",
        "At the end of training, we can thus estimate the targeted regularization estimate of  the ATE $\\hat{ATE_{TR}}$ as in TMLE:\n",
        "$$\\hat{ATE_{TR}}=\\frac{1}{N}\\sum_{i=1}^N{ h^*(\\Phi(x),1)}-{ h^*(\\Phi(x),0)}$$\n",
        "\n",
        "Note that because they solve the EIC estimating equation for the ATE, both TMLE and Targeted Regularization are doubly robust estimators.\n",
        "\n",
        "Again, the key difference between TMLE and Targeted Regularization is that in Targeted Regularization we are jointly tuning $h$ and $\\epsilon$ at the same time every batch, rather than fitting them completely in succession and plugging-in as in TMLE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yObUdoRvYqPG"
      },
      "source": [
        "## Implementing Targeted Regularization\n",
        "The rest of this tutorial is basically an annotated cut and paste from Shi's elegant repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK0bmUq6jP5J"
      },
      "source": [
        " We'll need to start by adding $\\epsilon$ as a parameter in our neural network. Shi does this by creating a [custom layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) she calls `EpsilonLayer`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHmzhAUwYndv"
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "class EpsilonLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(EpsilonLayer, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.epsilon = self.add_weight(name='epsilon',\n",
        "                                       shape=[1, 1],\n",
        "                                       initializer='RandomNormal',\n",
        "                                       #  initializer='ones',\n",
        "                                       trainable=True)\n",
        "        super(EpsilonLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        #note there is only one epsilon were just duplicating it for conformability\n",
        "        return self.epsilon * tf.ones_like(inputs)[:, 0:1]\n",
        "\n",
        "def make_dragonnet(input_dim, reg_l2):\n",
        "\n",
        "    x = Input(shape=(input_dim,), name='input')\n",
        "    # representation\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(x)\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_2')(phi)\n",
        "    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_3')(phi)\n",
        "\n",
        "    # HYPOTHESIS\n",
        "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
        "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
        "\n",
        "    # second layer\n",
        "    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_2')(y0_hidden)\n",
        "    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_2')(y1_hidden)\n",
        "\n",
        "    # third\n",
        "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
        "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
        "\n",
        "    #propensity prediction\n",
        "    #Note that the activation is actually sigmoid, but we will squish it in the loss function for numerical stability reasons\n",
        "    t_predictions = Dense(units=1,activation=None,name='t_prediction')(phi)\n",
        "    #Although the epsilon layer takes an input, it really just houses a free parameter. \n",
        "    epsilons = EpsilonLayer()(t_predictions)\n",
        "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,t_predictions,epsilons,phi])\n",
        "    model = Model(inputs=x, outputs=concat_pred)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip67SP_xUAGb"
      },
      "source": [
        "Now let's write the loss. You should be able to follow along from the Latex above. To save a bit of code we'll subclass the [`Base_Loss`](https://colab.research.google.com/drive/1gtOd0O0kJDMJe4emJCUaR7ZQRvrM53xa?authuser=2#scrollTo=0wgc7wTySg24&line=1&uniqifier=1) we implemented above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ow8gofOOp_f"
      },
      "source": [
        "class TarReg_Loss(Base_Loss):\n",
        "    #initialize instance attributes\n",
        "    def __init__(self, alpha=1,beta=1):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta=beta\n",
        "        self.name='tarreg_loss'\n",
        "\n",
        "    def split_pred(self,concat_pred):\n",
        "        #generic helper to make sure we dont make mistakes\n",
        "        preds={}\n",
        "        preds['y0_pred'] = concat_pred[:, 0]\n",
        "        preds['y1_pred'] = concat_pred[:, 1]\n",
        "        preds['t_pred'] = concat_pred[:, 2]\n",
        "        preds['epsilon'] = concat_pred[:, 3] #we're moving epsilon into slot three\n",
        "        preds['phi'] = concat_pred[:, 4:]\n",
        "        return preds\n",
        "\n",
        "    def calc_hstar(self,concat_true,concat_pred):\n",
        "        #step 2 above\n",
        "        p=self.split_pred(concat_pred)\n",
        "        y_true = concat_true[:, 0]\n",
        "        t_true = concat_true[:, 1]\n",
        "\n",
        "        t_pred = tf.math.sigmoid(concat_pred[:, 2])\n",
        "        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n",
        "        y_pred = t_true * p['y1_pred'] + (1 - t_true) * p['y0_pred']\n",
        "\n",
        "        #calling it cc for \"clever covariate\" as in SuperLearner TMLE literature\n",
        "        cc = t_true / t_pred - (1 - t_true) / (1 - t_pred)\n",
        "        h_star = y_pred + p['epsilon'] * cc\n",
        "        return h_star\n",
        "\n",
        "    def call(self,concat_true,concat_pred):\n",
        "        y_true = concat_true[:, 0]\n",
        "\n",
        "        standard_loss=self.standard_loss(concat_true,concat_pred)\n",
        "        h_star=self.calc_hstar(concat_true,concat_pred)\n",
        "        #step 3 above\n",
        "        targeted_regularization = tf.reduce_sum(tf.square(y_true - h_star))\n",
        "\n",
        "        # final\n",
        "        loss = standard_loss + self.beta * targeted_regularization\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-P3JBqLVQi"
      },
      "source": [
        "Now we update our callback so that it computes $h*$ and the final, plug-in $\\hat{ATE}_{\\text{TR}}$. Looking at the Latex may again be helpful. We can save some code lines by subclassing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVUuqs7lRrJ0"
      },
      "source": [
        "class TarReg_Metrics(AIPW_Metrics):\n",
        "    def __init__(self,data, verbose=0):   \n",
        "        super().__init__(data,verbose)\n",
        "\n",
        "    def split_pred(self,concat_pred):\n",
        "        preds={}\n",
        "        preds['y0_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 0])\n",
        "        preds['y1_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 1])\n",
        "        preds['t_pred'] = concat_pred[:, 2]\n",
        "        preds['epsilon'] = concat_pred[:, 3]\n",
        "        preds['phi'] = concat_pred[:, 4:]\n",
        "        return preds\n",
        "    \n",
        "    def compute_hstar(self,y0_pred,y1_pred,t_pred,t_true,epsilons):\n",
        "        #helper for calculating the targeted regularization cate\n",
        "        y_pred = t_true * y1_pred + (1 - t_true) * y0_pred\n",
        "        cc = t_true / t_pred - (1 - t_true) / (1 - t_pred)\n",
        "        h_star = y_pred + epsilons * cc\n",
        "        return h_star\n",
        "    \n",
        "    def TARREG_CATE(self,concat_pred):\n",
        "        #Final calculation of Targeted Regularization loss\n",
        "        p = self.split_pred(concat_pred)\n",
        "        t_pred = tf.math.sigmoid(p['t_pred'])\n",
        "        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi       \n",
        "        hstar_0=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.zeros_like(p['epsilon']),p['epsilon'])\n",
        "        hstar_1=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.ones_like(p['epsilon']),p['epsilon'])\n",
        "        return hstar_1-hstar_0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        concat_pred=self.model.predict(self.data['x'])\n",
        "        #Calculate Empirical Metrics        \n",
        "        aipw_pred=tf.reduce_mean(self.AIPW(concat_pred)); tf.summary.scalar('aipw', data=aipw_pred, step=epoch)\n",
        "        ate_pred=tf.reduce_mean(self.ATE(concat_pred)); tf.summary.scalar('ate', data=ate_pred, step=epoch)\n",
        "        tarreg_pred=tf.reduce_mean(self.TARREG_CATE(concat_pred)); tf.summary.scalar('tarreg_pred', data=tarreg_pred, step=epoch)\n",
        "        pehe_nn=self.PEHEnn(concat_pred); tf.summary.scalar('cate_nn_err', data=tf.sqrt(pehe_nn), step=epoch)\n",
        "        \n",
        "        #Simulation Metrics\n",
        "        ate_true=tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n",
        "        ate_err=tf.abs(ate_true-ate_pred); tf.summary.scalar('ate_err', data=ate_err, step=epoch)\n",
        "        aipw_err=tf.abs(ate_true-aipw_pred); tf.summary.scalar('aipw_err', data=aipw_err, step=epoch)\n",
        "        tarreg_err=tf.abs(ate_true-tarreg_pred); tf.summary.scalar('tarreg_err', data=tarreg_err, step=epoch)\n",
        "        pehe =self.PEHE(concat_pred); tf.summary.scalar('cate_err', data=tf.sqrt(pehe), step=epoch)\n",
        "        out_str=f' — ate_err: {ate_err:.4f}  — aipw_err: {aipw_err:.4f} — tarreg_err: {tarreg_err:.4f} — cate_err: {tf.sqrt(pehe):.4f} — cate_nn_err: {tf.sqrt(pehe_nn):.4f} '\n",
        "        \n",
        "        if self.verbose > 0: print(out_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n2McaONjge4"
      },
      "source": [
        "Cool. Now we can run it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XHRW0mOUOzK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, TerminateOnNaN\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "val_split=0.2\n",
        "batch_size=64\n",
        "verbose=1\n",
        "i = 0\n",
        "tf.random.set_seed(i)\n",
        "np.random.seed(i)\n",
        "yt = np.concatenate([data['ys'], data['t']], 1)\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
        "file_writer.set_as_default()\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
        "\n",
        "sgd_callbacks = [\n",
        "        TerminateOnNaN(),\n",
        "        EarlyStopping(monitor='val_loss', patience=40, min_delta=0.),\n",
        "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
        "                          min_delta=0., cooldown=0, min_lr=0),\n",
        "        tensorboard_callback,\n",
        "        TarReg_Metrics(data, verbose=verbose)    ]\n",
        "\n",
        "sgd_lr = 1e-5\n",
        "momentum = 0.9\n",
        "\n",
        "dragonnet_model=make_dragonnet(data['x'].shape[1],.01)\n",
        "tarreg_loss=TarReg_Loss(alpha=1)\n",
        "\n",
        "dragonnet_model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
        "                      loss=tarreg_loss,\n",
        "                 metrics=[tarreg_loss,tarreg_loss.regression_loss,tarreg_loss.treatment_acc])\n",
        "\n",
        "dragonnet_model.fit(x=data['x'],y=yt,\n",
        "                 callbacks=sgd_callbacks,\n",
        "                  validation_split=val_split,\n",
        "                  epochs=300,\n",
        "                  batch_size=batch_size,\n",
        "                  verbose=verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRPtHkQgKBlh"
      },
      "source": [
        "As usual we'll check things in TensorBoard. Again, we don't see that much of a difference in predicting the $ATE$ (`tarreg_err` vs. `ate_err`) but there is a big gain in `cate_err` on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo1XMfoX3F1v"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZGewnJcKGj3"
      },
      "source": [
        "# Confidence Intervals\n",
        "\n",
        "Because Targeted regularization is essentially TMLE, standard deviation of $\\sigma_{\\hat{ATE}}$ is the sample-corrected standard deviation of the EIC estimating equation, where\n",
        "$$\\sigma_{\\hat{ATE_{TR}}}=\\sqrt{\\frac{Var(IC_\\hat{ATE_{TR}})}{n}}$$ and,\n",
        "\n",
        "$$Var(IC_\\hat{ATE_{TR}}) = Var[(\\frac{T}{\\pi(x,1)}-\\frac{1-T}{\\pi(x,0)})(Y-h^*(x,T))+(h^*(x,1)-h^*(x,0))-\\hat{ATE_{TR}}]$$\n",
        "\n",
        "Alternatively, you can estimate confidence intervals through bootstrapping.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-wJnNyRN8Ti"
      },
      "source": [
        "# Small caveat\n",
        "\n",
        "Note that semi-parametric theory is focused on estimating the $ATE$ parameter of the treatment effect distribution, and not heterogeneous treatment effects. In fact, the Dragonnet paper does not report $CATE$ estimates because this is not the focus of the paper. But in this toy example, it does seems like Targeted Regularization improved prediction on the $CATE$ as well. It makes sense that creating an explicit treatment effect loss would improve counterfactual prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgNiQXN0kGLb"
      },
      "source": [
        "# That's it!\n",
        "\n",
        "In this tutorial we:\n",
        "\n",
        "- Introduced treatment modeling and the Dragonnet architecture.\n",
        "\n",
        "- Built a custom object oriented loss for Dragonnet and adapted our callback to estimate the AIPW\n",
        "\n",
        "- Explained the TMLE and Targeted Regularization algorithms and implemented targeted regularization.\n",
        "\n",
        "# Up next...\n",
        "\n",
        "In the final tutorial, we introduce Counterfactual Regression Network (CFRNet) described in [Shalit et al., 2017](https://arxiv.org/abs/1606.03976), [Johansson et al. 2018](https://arxiv.org/abs/1903.03448), and [Johansson et al., 2020](https://arxiv.org/abs/2001.07426). Instead of propensity modeling, CFRNet uses integral probability metrics (IPMs) to bound the counterfactual generalization error. A variant called weighted CFRNet combines IPMs with propensity weighting.\n"
      ]
    }
  ]
}